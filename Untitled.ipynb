{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate,\n",
    "                                    Dense, Dropout, Flatten, Input, Lambda, Reshape)\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "img_shape = (img_rows, img_cols, channels) # 입력 이미지 차원\n",
    "\n",
    "z_dim = 100 # 생성자의 입력으로 사용할 잡음 벡터의 크기\n",
    "\n",
    "num_classes = 10 # 데이터셋에 있는 클래스 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, num_labeled):\n",
    "        \n",
    "        self.num_labeled = num_labeled # 훈련에 사용할 레이블된 샘플 개수 \n",
    "        \n",
    "        # MNIST 데이터셋 적재\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = mnist.load_data()\n",
    "        \n",
    "        def preprocess_imgs(x):\n",
    "            x = (x.astype(np.float32) - 127.5) / 127.5\n",
    "            x = np.expand_dims(x, axis=3)\n",
    "            return x\n",
    "        \n",
    "        def preprocess_labels(y):\n",
    "            return y.reshape(-1, 1)\n",
    "        \n",
    "        # 훈련 데이터\n",
    "        self.x_train = preprocess_imgs(self.x_train)\n",
    "        self.y_train = preprocess_labels(self.y_train)\n",
    "        \n",
    "        # 테스트 데이터\n",
    "        self.x_test = preprocess_imgs(self.x_test)\n",
    "        self.y_test = preprocess_labels(self.y_test)\n",
    "        \n",
    "    def batch_labeled(self, batch_size):\n",
    "        # 레이블된 이미지와 레이블된 랜덤 배치 만들기\n",
    "        idx = np.random.randint(0, self.num_labeled, batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        labels = self.y_train[idx]\n",
    "        return imgs, labels\n",
    "    \n",
    "    def batch_unlabeled(self, batch_size):\n",
    "        # 레이블이 없는 이미지의 랜덤 배치 만들기\n",
    "        idx = np.random.randint(self.num_labeled, self.x_train.shape[0],\n",
    "                               batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        return imgs\n",
    "    \n",
    "    def training_set(self):\n",
    "        x_train = self.x_train[range(self.num_labeled)]\n",
    "        y_train = self.y_train[range(self.num_labeled)]\n",
    "        return x_train, y_train\n",
    "    \n",
    "    def test_set(self):\n",
    "        return self.x_test, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "num_labeled = 100\n",
    "\n",
    "dataset = Dataset(num_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
    "    # 완결 연결 층을 사용해 입력을 7 x 7 x 256 크기 텐서로 바꿉니다.\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "    \n",
    "    # 7 x 7 x 256 에서 14 x 14 x 128 텐서로 바꾸는 전치 합성곱 층\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    \n",
    "    # 배치 정규화\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # LeakyReLU 활성화 함수\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # 14 x 14 x 128에서 14 x 14 x 64 텐서로 바꾸는 전치 합성곱 층\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # 14 x 14 x 64 에서 28 x 28 x 1 텐서로 바꾸는 전치 합성곱 층\n",
    "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    \n",
    "    # tanh 활성화 함수\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_net(img_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # 28 x 28 x 1 에서 14 x 14 x 32 텐서로 바꾸는 합성곱 층\n",
    "    model.add(\n",
    "        Conv2D(32,\n",
    "              kernel_size=3,\n",
    "              strides=2,\n",
    "              input_shape=img_shape,\n",
    "              padding=\"same\"))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # 14 x 14 x 32 에서 7 x 7 x 64 텐서로 바꾸는 합성곱 층\n",
    "    model.add(\n",
    "        Conv2D(64,\n",
    "              kernel_size=3,\n",
    "              strides=2,\n",
    "              input_shape=img_shape,\n",
    "              padding=\"same\"))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(\n",
    "        Conv2D(128,\n",
    "              kernel_size=3,\n",
    "              strides=2,\n",
    "              input_shape=img_shape,\n",
    "              padding=\"same\"))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # 드롭아웃\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # 텐서 펼치기\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # num_classes개의 뉴런을 가진 완전 연결 층\n",
    "    model.add(Dense(num_classes))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_supervised(discriminator_net):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(discriminator_net)\n",
    "    \n",
    "    # 진짜 클래스에 대한 예측 확률을 출력하는 소프트맥스 활성화 함수\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_unsupervised(discriminator_net):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(discriminator_net)\n",
    "    \n",
    "    def predict(x):\n",
    "        # 진짜 클래스에 대한 확률 분포를 진짜 대 가짜의 이진 확률로 변환합니다.\n",
    "        prediction = 1.0 - (1.0 /\n",
    "                           (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
    "        \n",
    "        return prediction\n",
    "        \n",
    "    # 앞서 정의한 진짜 대 가짜 확률을 출력하는 뉴런\n",
    "    model.add(Lambda(predict))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(generator) # 생성자와 판별자 모델을 연결하기\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 판별자 기반 모델: 이 층들은 지도 학습 훈련과 비지도 학습 훈련에 공유됩니다.\n",
    "discriminator_net = build_discriminator_net(img_shape)\n",
    "\n",
    "# 지도 학습 훈련을 위해 판별자를 만들고 컴파일합니다.\n",
    "discriminator_supervised = build_discriminator_supervised(discriminator_net)\n",
    "discriminator_supervised.compile(loss = \"categorical_crossentropy\",\n",
    "                                 metrics=[\"accuracy\"],\n",
    "                                 optimizer=Adam(learning_rate=0.0003))\n",
    "\n",
    "# 비지도 학습 훈련을 위해 판별자를 만들고 컴파일합니다.\n",
    "discriminator_unsupervised = build_discriminator_unsupervised(\n",
    "                                discriminator_net)\n",
    "discriminator_unsupervised.compile(loss=\"binary_crossentropy\",\n",
    "                                  optimizer=Adam())\n",
    "\n",
    "# 생성자를 만듭니다.\n",
    "generator = build_generator(z_dim)\n",
    "\n",
    "# 생성자 훈련을 위해 판별자의 모델 파라미터를 동결합니다.\n",
    "discriminator_unsupervised.trainable = False\n",
    "\n",
    "# 생성자를 훈련하기 위해 고정된 판별자로 GAN 모델을 만들고 컴파일합니다. 참고: 비지도 학습용 판별자를 사용하세요\n",
    "gan = build_gan(generator, discriminator_unsupervised)\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_losses = []\n",
    "iteration_checkpoints = []\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "    \n",
    "    # 진짜 이미지의 레이블: 모두 1\n",
    "    real = np.ones((batch_size, 1))\n",
    "    \n",
    "    # 가짜 이미지의 레이블: 모두 0\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        # 레이블된 샘플을 가져옵니다.\n",
    "        imgs, labels = dataset.batch_labeled(batch_size)\n",
    "        \n",
    "        # 레이블을 원-핫 인코딩합니다.\n",
    "        labels = to_categorical(labels, num_classes=num_classes)\n",
    "        \n",
    "        # 레이블이 없는 샘플을 가져옵니다.\n",
    "        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
    "        \n",
    "        # 가짜 이미지의 배치를 생성합니다\n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        \n",
    "        gen_imgs = generator.predict(z)\n",
    "        \n",
    "        # 레이블된 진짜 샘플에서 훈련합니다.\n",
    "        d_loss_supervised, accuracy = discriminator_supervised.train_on_batch(imgs, labels)\n",
    "        \n",
    "        # 레이블이 없는 진짜 샘플에서 훈련합니다.\n",
    "        d_loss_real = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n",
    "        \n",
    "        # 가짜 샘플에서 훈련합니다.\n",
    "        d_loss_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n",
    "        \n",
    "        d_loss_unsupervised = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # 가짜 이미지의 배치를 생성합니다.\n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict(z)\n",
    "        \n",
    "        # 생성자를 훈련합니다.\n",
    "        g_loss = gan.train_on_batch(z, np.ones((batch_size, 1)))\n",
    "        \n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            \n",
    "            supervised_losses.append(d_loss_supervised)\n",
    "            iteration_checkpoints.append(iteration + 1)\n",
    "            \n",
    "            print(\n",
    "                \"%d [D 손실: %.4f, 정확도: %.2f%%] [D 손실: %.4f] [G 손실: %f]\" %\n",
    "                (iteration + 1, d_loss_supervised, 100 * accuracy,\n",
    "                d_loss_unsupervised, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ae2597780031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-075f2a1cf986>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(iterations, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# 레이블된 진짜 샘플에서 훈련합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1593\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[1;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m    721\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         gen_experimental_dataset_ops.make_data_service_iterator(\n",
      "\u001b[0;32m~/.venv/tf2.3.0-keras2.4.0-py3.7-cuda10.1/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3005\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3006\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MakeIterator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m         tld.op_callbacks, dataset, iterator)\n\u001b[0m\u001b[1;32m   3008\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = 8000\n",
    "batch_size = 32\n",
    "sample_interval = 800\n",
    "\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.3.0-keras2.4.0-py3.7-cuda10.1",
   "language": "python",
   "name": "tf2.3.0-keras2.4.0-py3.7-cuda10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
